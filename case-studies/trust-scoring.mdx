'''import { CaseStudyLayout } from "@/components/CaseStudyLayout";

export const metadata = {
  title: "Real-Time Trust & Risk Scoring Platform",
  description: "A deep dive into building a real-time risk evaluation system with cache-first hot paths and comprehensive failure handling."
}

export default ({ children }) => <CaseStudyLayout metadata={metadata}>{children}</CaseStudyLayout>;

## Problem

To build a real-time risk evaluation system that scores user behavior with cache-first hot paths and comprehensive failure handling.

## Constraints & SLOs

- **Latency:** p99 latency of <100ms for risk scoring requests.
- **Throughput:** 10,000+ requests per second.
- **Availability:** 99.99% uptime.
- **Consistency:** Eventual consistency is acceptable for most data, but strong consistency is required for critical user data.

## Architecture

The system is built around a stream processing pipeline using Kafka. The main components are:

- **Ingestion Service:** A lightweight service that receives user behavior events and publishes them to a Kafka topic.
- **Scoring Service:** A stream processing application that consumes events from Kafka, enriches them with data from Redis and Postgres, and calculates a risk score.
- **API Service:** A service that exposes an API for other services to query the risk score for a user.

![Architecture Diagram](https://via.placeholder.com/800x400.png?text=Architecture+Diagram)

## Data Model

- **User Profile:** Stores user information, including their current risk score. Stored in Postgres.
- **User Behavior Events:** A log of all user behavior events. Stored in Kafka and archived to S3.
- **Feature Store:** A store of pre-computed features for each user. Stored in Redis for fast access.

![Data Model](https://via.placeholder.com/800x300.png?text=Data+Model)

## Key Design Choices & Tradeoffs

- **Cache-First Hot Path:** For the most common and latency-sensitive requests, we use a cache-first hot path. The scoring service first checks Redis for the required data. If the data is not in Redis, it falls back to Postgres. This adds complexity but is necessary to meet our latency SLO.
- **Append-Only Audit Logs:** All changes to the user's risk score are recorded in an append-only audit log. This provides a clear audit trail and makes it easy to debug issues.
- **Rate Limiting, Circuit Breakers, and Bulkheads:** We use a combination of these patterns to protect our system from overload and to prevent cascading failures. Rate limiting is used to prevent any single user from overwhelming the system. Circuit breakers are used to prevent a single failing service from taking down the entire system. Bulkheads are used to isolate different parts of the system from each other.

## Failure Modes & Mitigations

- **Ingestion Service Failure:** The ingestion service is stateless and can be easily scaled horizontally. If a single instance fails, the load balancer will redirect traffic to other instances.
- **Scoring Service Failure:** The scoring service is a stateful stream processing application. We use Kafka's consumer group mechanism to ensure that each partition is only processed by one consumer at a time. If a consumer fails, another consumer in the group will take over processing its partitions.
- **API Service Failure:** The API service is stateless and can be easily scaled horizontally.

## Observability

- **Metrics:** We track the latency and throughput of each service, as well as the end-to-end latency of the system.
- **Logging:** We use structured logging to make it easy to search and analyze our logs.
- **Tracing:** We use distributed tracing to track requests as they flow through the system.

## Results

- **Cache-first hot path design**
- **Kafka event ingestion**
- **Append-only audit logs**
- **Rate limiting + circuit breakers**
- **Bulkhead isolation**

## Run locally in 60 seconds

```bash
docker-compose up -d
./mvnw spring-boot:run
```
'''
